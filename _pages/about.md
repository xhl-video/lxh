---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html

---

Xianhang Li
======

Hi! I’m a Ph.D student in computer science  at [ University of California, Santa Cruz](https://www.soe.ucsc.edu/departments/computer-science-and-engineering).  My adviser is Prof. [Cihang Xie](https://cihangxie.github.io/).  My research interest is on computer vision and deep learning, with particular interests in action recognition, video classification and video synthesis.



My resume can be downloaded through this link [CV](https://github.com/xhl-video/xianhangli/blob/master/files/Xianhang_Li_s_Resume.pdf).



News
======

+ [new] We release Recap-DataComp-1B, where we use a LLaMA-3-powered LLaVA model to recaption the entire 1.3 billion images from DataComp-1B.

+ [2024/10]  One paper is accepted by NeurIPS 2024.

+ [2024/9]  EVP is accepted by TMLR 2024.

+ [2024/5] I am honored to be selected as the only  Jack Baskin and Peggy Downes-Baskin Fellowship recipient.

+ [2024/2] Two papers (AdvXL, L2B) are accepted by CVPR 2024.

+ [2023/9] CLIPA is accepted by NeurIPS 2023. In addition, we release our best model, CLIPA-G/14, which attains 83.0% zero-shot ImageNet top-1 accuracy.

+ [2022/10/24] One paper was accepted in NeruaIPS ML Safty Workshop 2022.

+ [2022/7/8]  One paper was accepted in ECCV 2022.

+ [2022/6/13]  Started my summer intern at ByteDance with Dr. [Peng Wang](https://pengwangucla.github.io/peng-wang.github.io/).

+ [2022/1/28]  One paper was accepted in ICLR 2022.

+ [2021/10/4]  One paper was accepted in WACV 2022.

+ [2021/06/13]  I will join UCSC as a Ph.D. student!

+ [2021/01/13]  One paper was accepted in ICLR 2021.

+ [2020/02/24]  One paper was accepted in CVPR 2020.


Publications [[Full List](https://scholar.google.com/citations?user=YKpFz4YAAAAJ&hl=zh-CN)]
======

___
<div class="row" xmlns="http://www.w3.org/1999/html">
  <div class="column left">
    <img align="left" width="100%"  src="https://cihangxie.github.io/images/li2024recap.jpeg?raw=true">  
  </div>
   <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>What If We Recaption Billions of Web Images with LLaMA-3?</strong><br/>
     <u>Xianhang Li</u>*, Haoqin Tu*, Mude Hui*, Zeyu Wang*, Bingchen Zhao*, Junfei Xiao, Sucheng Ren, Jieru Mei, Qing Liu, Huangjie Zheng, Yuyin Zhou, Cihang Xie<br/>
       arxiv, 2024.<br/>   
        [<a href="https://arxiv.org/pdf/2406.08478.pdf">PDF</a>]
        [<a href="https://www.haqtu.me/Recap-Datacomp-1B/">Code</a>]
    </p>
  </div>
</div>

___
<div class="row" xmlns="http://www.w3.org/1999/html">
  <div class="column left">
    <img align="left" width="100%"  src="https://cihangxie.github.io/images/yang2024crate.png?raw=true">  
  </div>
   <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>Scaling White-Box Transformers for Vision</strong><br/>
      Jinrui Yang*,  <u>Xianhang Li</u>*, Druv Pai, Yuyin Zhou, Yi Ma, Yadong Yu, Cihang Xie<br/>
       NeurIPS, 2024.<br/>   
        [<a href="https://arxiv.org/pdf/2405.20299.pdf">PDF</a>]
        [<a href="https://rayjryang.github.io/CRATE-alpha/">Code</a>]
    </p>
  </div>
</div>
___
<div class="row" xmlns="http://www.w3.org/1999/html">
  <div class="column left">
    <img align="left" width="100%"  src="https://cihangxie.github.io/images/wang2024advxl.png?raw=true">  
  </div>
   <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>Revisiting Adversarial Training at Scale</strong><br/>
      Zeyu Wang*, <u>Xianhang Li</u>*, Hongru Zhu, Cihang Xie<br/>
       CVPR, 2024.<br/>   
        [<a href="https://arxiv.org/pdf/2401.04727.pdf">PDF</a>]
        [<a href="https://github.com/UCSC-VLAA/AdvXL">Code</a>]
    </p>
  </div>
</div>

___
<div class="row" xmlns="http://www.w3.org/1999/html">
  <div class="column left">
    <img align="left" width="100%"  src="https://cihangxie.github.io/images/zhou2024L2B.png?raw=true">  
  </div>
   <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>Learning to Bootstrap for Combating Label Noise</strong><br/>
      Yuyin Zhou*, <u>Xianhang Li</u>*, Fengze Liu, Xuxi Chen, Lequan Yu, Cihang Xie, Matthew P. Lungren, Lei Xing<br/>
       CVPR, 2024.<br/>   
        [<a href="https://arxiv.org/pdf/2202.04291.pdf">PDF</a>]
        [<a href="https://github.com/yuyinzhou/L2B">Code</a>]
    </p>
  </div>
</div>

___
<div class="row">
  <div class="column left">
    <img align="left" width="100%"  src="https://cihangxie.github.io/images/wu2024evp.png?raw=true">  
  </div>
   <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>	
Unleashing the Power of Visual Prompting At the Pixel Level</strong><br/>
      Junyang Wu*, <u>Xianhang Li</u>*, Chen Wei, Huiyu Wang, Alan Yuille, Yuyin Zhou, Cihang Xie<br/>
       TMLR, 2024.<br/>   
        [<a href="https://arxiv.org/abs/2212.10556">PDF</a>]
        [<a href="https://github.com/UCSC-VLAA/EVPA">Code</a>]
    </p>
  </div>
</div>

___
<div class="row">
  <div class="column left">
    <img align="left" width="100%"  src="https://cihangxie.github.io/images/li2023clipav2.png?raw=true">  
  </div>
   <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>	
CLIPA-v2: Scaling CLIP Training with 81.1% Zero-shot ImageNet Accuracy within a $10,000 Budget; An Extra $4,000 Unlocks 81.8% Accuracy</strong><br/>
       <u>Xianhang Li</u>*,  Zeyu Wang* and Cihang Xie<br/>
       NeurIPS R0-FoMo Workshop, 2023.<br/>   
        [<a href="https://arxiv.org/pdf/2306.15658.pdf">PDF</a>]
        [<a href="https://github.com/UCSC-VLAA/CLIPA">Code</a>]
    </p>
  </div>
</div>

___

<div class="row">
  <div class="column left">
    <img align="left" width="100%"  src="https://github.com/UCSC-VLAA/CLIPA/blob/master/clipa_jax/figs/inverse_scaling_law.png?raw=true">  
  </div>
   <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>An Inverse Scaling Law for CLIP Training</strong><br/>
       <u>Xianhang Li</u>*,  Zeyu Wang* and Cihang Xie<br/>
       NeurIPS 2023.<br/>   
        [<a href="https://arxiv.org/abs/2305.07017">PDF</a>]
        [<a href="https://github.com/UCSC-VLAA/CLIPA">Code</a>]
    </p>
  </div>
</div>
___

<div class="row">
  <div class="column left">
    <img align="left" width="100%"  src="https://github.com/xhl-video/xianhangli/blob/master/images/eccv_method.png?raw=true">  
  </div>
   <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>In Defense of Image Pre-Training for Spatiotemporal Recognition</strong><br/>
       <u>Xianhang Li</u>,  Huiyu Wang, Chen Wei,  Jieru Mei, Alan Yuille, Yuyin Zhou and Cihang Xie<br/>
        European Conference on Computer Vision   (ECCV'22), 2022.<br/>   
        [<a href="https://arxiv.org/abs/2205.01721">PDF</a>]
        [<a href="https://github.com/UCSC-VLAA/Image-Pretraining-for-Video">Code</a>]
    </p>
  </div>
</div>
___

<div class="row">
  <div class="column left">
    <img align="left" width="100%"  src="https://github.com/xhl-video/xianhangli/blob/master/images/overall.png?raw=true">  
  </div>
   <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>Pose-guided Generative Adversarial Net for Novel View Action Synthesis</strong><br/>
      <u>Xianhang Li</u>, Junhao Zhang, Kunchang Li, Shruti Vyas, Yogesh S Rawat<br/>
       Winter Conference on Applications of Computer Visions   (WACV'22), 2022.<br/>
        [<a href="https://arxiv.org/abs/2110.07993">PDF</a>]
    </p>
  </div>
</div>


___

<div class="row">
  <div class="column left">
    <img align="left" width="100%"  src="https://github.com/xhl-video/xianhangli/blob/master/images/Ctnet.png?raw=true">  
  </div>
   <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>CT-Net: Channel Tensorization Network for Video Classification</strong><br/>
      Kunchang Li*, <u>Xianhang Li</u>*, Yali Wang*, Jun Wang, Yu Qiao<br/>
     International Conference on Learning Representations   (ICLR'21), 2021.<br/>
        [<a href="https://openreview.net/pdf?id=UoaQUQREMOs">PDF</a>]
        [<a href="https://github.com/Andy1621/CT-Net">Code</a>]
    </p>
  </div>
</div>

___


<div class="row">
  <div class="column left">
    <img align="left" width="100%" src="https://github.com/xhl-video/xianhangli/blob/master/images/smallbig.png?raw=true">  
  </div>
  <div class="column middle">&nbsp;</div>
  <div class="column right">
    <p>
      <strong>SmallBigNet: Integrating Core and Contextual Views for Video Classification</strong><br/>
       <u>Xianhang Li</u>*, Yali Wang*, Zhipeng Zhou*, Yu Qiao<br/>
      Computer Vision and Pattern Recognition  (CVPR'20), 2020.<br/>
     [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Li_SmallBigNet_Integrating_Core_and_Contextual_Views_for_Video_Classification_CVPR_2020_paper.pdf">PDF</a>]
      [<a href="https://github.com/xhl-video/SmallBigNet">Code</a>]
    </p>
  </div>
</div>

___

&nbsp;

Experience 
======

+ **ByteDance Intelligent Creation Lab**  

  **Research Intern      　&nbsp;  &nbsp;       Moutain view, USA,  2022.06 - Present**   
  
  Efficient Video Training  &nbsp;  &nbsp; One paper was submitted to **CVPR2023**

  


+ **Center for Research in Computer Vision(CRCV) in UCF**  

  **Research Assistant      　&nbsp;  &nbsp;       Orlando, USA,  2020.05 - 2020.08**   
  
  Cross-View Video Synthesis  &nbsp;  &nbsp; One paper was accepted to **WACV2022**

  


+ **Multimedia Research Center(MMLAB) in SIAT**  

  **Research Assistant       　&nbsp; &nbsp;       Shenzhen, China, 2018.10 - 2020.10** 
  
  Video Classification    　&nbsp; &nbsp; One paper was submitted to **ICLR2021**; the other was published on **CVPR2020**


  


+ **Queen Mary University of London**

  **Research Assistant         　&nbsp; &nbsp;      London , UK, 2018.06 - 2018.10**   

  
&nbsp;

Education
======
+  **2021.09 - Present**
Ph.D. in Computer Science and Engineering, University of California, Santa Cruz (UCSC), Santa Cruz, USA
advised by Prof. [Cihang Xie](https://cihangxie.github.io/)

+  **2019.08 - 2021.05**  
M.Sc. in Computer Science, University of Central Florida (UCF), Orlando, USA  
GPA: 3.89/4.0  
advised by Prof. [Yogesh Singh Rawat](https://www.crcv.ucf.edu/person/rawat/) in [Center for Research in Computer Vision](https://www.crcv.ucf.edu/), supported by Prof. [Jun Wang](http://www.cass.eecs.ucf.edu/jun-wang/).

+  **2014.09 - 2018.07**  
B.E. in Telecommunications Engineering and Management, Beijing University of Posts and Telecommunications(BUPT), Beijing, China  

&nbsp;

Moments
======
My girlfriend and I adopted a cute cat. His name is Turing! He is also one of the mentors in my family.

<img src="https://github.com/xhl-video/xianhangli/blob/master/images/turing.jpeg?raw=true" alt="img"  width="40%"  style="zoom:70%;" />



<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=BbTMKt2tN1gS1S9RBpsvcC2nOdzNwrGUKj7gwvLtDfE&cl=ffffff&w=a"></script>

